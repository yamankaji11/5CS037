{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VQXNlmd6kjc9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import load_iris, load_wine, fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Custom Vs. Scikit Learn Built Decision Tree\n",
        "#Building a Custom Decision Tree with Information Gain\n",
        "\n",
        "class CustomDecisionTree:\n",
        "    def __init__(self, max_depth=None):\n",
        "        self.max_depth = max_depth\n",
        "        self.tree = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.tree = self._build_tree(X, y)\n",
        "\n",
        "    def _build_tree(self, X, y, depth=0):\n",
        "        num_samples, num_features = X.shape\n",
        "        unique_classes = np.unique(y)\n",
        "\n",
        "        # Stopping conditions\n",
        "        if len(unique_classes) == 1:\n",
        "            return {\"class\": unique_classes[0]}\n",
        "\n",
        "        if self.max_depth is not None and depth >= self.max_depth:\n",
        "            return {\"class\": np.bincount(y).argmax()}\n",
        "\n",
        "        best_info_gain = -float(\"inf\")\n",
        "        best_split = None\n",
        "\n",
        "        for feature_idx in range(num_features):\n",
        "            thresholds = np.unique(X[:, feature_idx])\n",
        "\n",
        "            for threshold in thresholds:\n",
        "                left_mask = X[:, feature_idx] <= threshold\n",
        "                right_mask = ~left_mask\n",
        "\n",
        "                if len(y[left_mask]) == 0 or len(y[right_mask]) == 0:\n",
        "                    continue\n",
        "\n",
        "                info_gain = self._information_gain(\n",
        "                    y, y[left_mask], y[right_mask]\n",
        "                )\n",
        "\n",
        "                if info_gain > best_info_gain:\n",
        "                    best_info_gain = info_gain\n",
        "                    best_split = {\n",
        "                        \"feature_idx\": feature_idx,\n",
        "                        \"threshold\": threshold,\n",
        "                        \"left_mask\": left_mask,\n",
        "                        \"right_mask\": right_mask,\n",
        "                    }\n",
        "\n",
        "        if best_split is None:\n",
        "            return {\"class\": np.bincount(y).argmax()}\n",
        "\n",
        "        left_tree = self._build_tree(\n",
        "            X[best_split[\"left_mask\"]],\n",
        "            y[best_split[\"left_mask\"]],\n",
        "            depth + 1,\n",
        "        )\n",
        "\n",
        "        right_tree = self._build_tree(\n",
        "            X[best_split[\"right_mask\"]],\n",
        "            y[best_split[\"right_mask\"]],\n",
        "            depth + 1,\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"feature_idx\": best_split[\"feature_idx\"],\n",
        "            \"threshold\": best_split[\"threshold\"],\n",
        "            \"left_tree\": left_tree,\n",
        "            \"right_tree\": right_tree,\n",
        "        }\n",
        "\n",
        "    def _information_gain(self, parent, left, right):\n",
        "        parent_entropy = self._entropy(parent)\n",
        "        left_entropy = self._entropy(left)\n",
        "        right_entropy = self._entropy(right)\n",
        "\n",
        "        weighted_entropy = (\n",
        "            len(left) / len(parent) * left_entropy\n",
        "            + len(right) / len(parent) * right_entropy\n",
        "        )\n",
        "\n",
        "        return parent_entropy - weighted_entropy\n",
        "\n",
        "    def _entropy(self, y):\n",
        "        probs = np.bincount(y) / len(y)\n",
        "        return -np.sum(probs * np.log2(probs + 1e-9))\n",
        "\n",
        "    def predict(self, X):\n",
        "        return [self._predict_single(x, self.tree) for x in X]\n",
        "\n",
        "    def _predict_single(self, x, tree):\n",
        "        if \"class\" in tree:\n",
        "            return tree[\"class\"]\n",
        "\n",
        "        if x[tree[\"feature_idx\"]] <= tree[\"threshold\"]:\n",
        "            return self._predict_single(x, tree[\"left_tree\"])\n",
        "        else:\n",
        "            return self._predict_single(x, tree[\"right_tree\"])"
      ],
      "metadata": {
        "id": "2XYhYHuilDgQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load and Split the IRIS Dataset\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "1YP1INB_la5B"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train & Evaluate Custom Decision Tree\n",
        "\n",
        "custom_tree = CustomDecisionTree(max_depth=3)\n",
        "custom_tree.fit(X_train, y_train)\n",
        "\n",
        "y_pred_custom = custom_tree.predict(X_test)\n",
        "accuracy_custom = accuracy_score(y_test, y_pred_custom)\n",
        "\n",
        "print(f\"Custom Decision Tree Accuracy: {accuracy_custom:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_c7p7OSlgZA",
        "outputId": "4218012c-9f71-43ae-cd15-3bc9957dec2d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom Decision Tree Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Train & Evaluate Scikit-Learn Decision Tree\n",
        "\n",
        "sklearn_tree = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "sklearn_tree.fit(X_train, y_train)\n",
        "\n",
        "y_pred_sklearn = sklearn_tree.predict(X_test)\n",
        "accuracy_sklearn = accuracy_score(y_test, y_pred_sklearn)\n",
        "print(f\"Scikit-learn Decision Tree Accuracy: {accuracy_sklearn:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5cz9zTBllBS",
        "outputId": "0a5bbbce-1645-456d-cee6-ec8a22ecdce9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scikit-learn Decision Tree Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy Comparison\n",
        "\n",
        "print(\"Accuracy Comparison:\")\n",
        "print(f\"Custom Decision Tree: {accuracy_custom:.4f}\")\n",
        "print(f\"Scikit-learn Decision Tree: {accuracy_sklearn:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jbjkHCalxsH",
        "outputId": "9b814e41-8af1-4bed-87a6-ec9c18419909"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Comparison:\n",
            "Custom Decision Tree: 1.0000\n",
            "Scikit-learn Decision Tree: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ensemble Methods and Hyperparameter Tuning(Wine Dataset)\n",
        "#Implement Classification Models:\n",
        "\n",
        "wine = load_wine()\n",
        "X = wine.data\n",
        "y = wine.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "dt.fit(X_train, y_train)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "y_pred_dt = dt.predict(X_test)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "print(\"Decision Tree F1 Score:\", f1_score(y_test, y_pred_dt, average=\"weighted\"))\n",
        "print(\"Random Forest F1 Score:\", f1_score(y_test, y_pred_rf, average=\"weighted\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfqLeHB4l2ZD",
        "outputId": "21cecffa-aaf3-4d2f-d66e-5c637fcf5f70"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree F1 Score: 0.9439974457215836\n",
            "Random Forest F1 Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameter Tuning (Random Forest â€“ GridSearchCV)\n",
        "\n",
        "param_grid = {\n",
        "    \"n_estimators\": [50, 100, 200],\n",
        "    \"max_depth\": [None, 5, 10],\n",
        "    \"min_samples_split\": [2, 5, 10],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    RandomForestClassifier(random_state=42),\n",
        "    param_grid,\n",
        "    cv=5,\n",
        "    scoring=\"f1_weighted\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best F1 Score:\", grid_search.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLsjLHQqmNSo",
        "outputId": "dc5e89ed-29a7-4588-ab22-5dbb8cc1948f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Best F1 Score: 0.9782952128219708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Implement Regression Model\n",
        "#Train a Decision Tree Regressor and a Random Forest Regressor using scikit-learn.\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "X = housing.data\n",
        "y = housing.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "dt_reg = DecisionTreeRegressor(random_state=42)\n",
        "rf_reg = RandomForestRegressor(random_state=42)\n",
        "\n",
        "dt_reg.fit(X_train, y_train)\n",
        "rf_reg.fit(X_train, y_train)\n",
        "\n",
        "print(\"Decision Tree MSE:\", mean_squared_error(y_test, dt_reg.predict(X_test)))\n",
        "print(\"Random Forest MSE:\", mean_squared_error(y_test, rf_reg.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLt_AVOUnFde",
        "outputId": "0e727b19-6047-479c-ae98-d4046239af1d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree MSE: 0.495235205629094\n",
            "Random Forest MSE: 0.2553684927247781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Identify three parameters for Random Forest Regressio and Perform hyperparameter tuning using RandomSearchCV to optimize these parameters.\n",
        "\n",
        "param_dist = {\n",
        "    \"n_estimators\": [50, 100, 200],\n",
        "    \"max_depth\": [None, 10, 20, 30],\n",
        "    \"max_features\": [\"sqrt\", \"log2\"],\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    RandomForestRegressor(random_state=42),\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=10,\n",
        "    cv=5,\n",
        "    scoring=\"neg_mean_squared_error\",\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "print(\"Best MSE:\", -random_search.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eeo7RrsznW5P",
        "outputId": "889c8774-1dbd-4cf1-e154-9eae803abfb5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'n_estimators': 100, 'max_features': 'log2', 'max_depth': 20}\n",
            "Best MSE: 0.2458085852355155\n"
          ]
        }
      ]
    }
  ]
}